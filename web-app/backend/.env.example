PORT=3001
NODE_ENV=development

# Ollama LLM (LlamaIndex agent) configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=gpt-oss:20b
OLLAMA_EMBED_MODEL=qwen3-embedding:0.6b
OLLAMA_RERANK_MODEL=sam860/qwen3-reranker:0.6b-F16

# RAG configuration
FIRMWARE_DOCS_DIR=../../stm32
FIRMWARE_INDEX_DIR=./agent/index_stm32
RAG_CHUNK_SIZE=1400
RAG_CHUNK_OVERLAP=180

# Optional: override KiCad CLI path for render export
KICAD_CLI_PATH=/Applications/KiCad/KiCad.app/Contents/MacOS/kicad-cli
# Optional: control layers used for SVG render export
KICAD_RENDER_LAYERS=F.Cu,B.Cu,F.SilkS,B.SilkS,F.Mask,B.Mask,Edge.Cuts

# Optional: limit raw KiCad payload size sent to LLM
LLM_MAX_FILE_CHARS=120000
LLM_MAX_TOTAL_CHARS=400000

# Optional: override the Python used for the LlamaIndex agent.
# LLAMA_AGENT_PYTHON=/path/to/python
# Optional: override the LlamaIndex agent script path.
# LLAMA_AGENT_SCRIPT=/absolute/path/to/llamaindex_agent.py
# Optional: timeout in milliseconds for the agent process.
# LLAMA_AGENT_TIMEOUT_MS=45000
